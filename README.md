1)  Выбор метрики и обоснование ее выбора:<br />
 Для задачи была выбрана простейшая MSE, так как в данных довольно много категориальных признаков и не так много выбросов. 

Лучшая модель выбирается по MSE на train этапе.
Подсчет MAE и R2 осуществляется на валидационной выборке, уже на обученной модели, результаты сохраняются в директории reports, графики - в reports/figures.

2)  Разделение данных train/val<br />
Происходит в стейдже preprocess_data, с помощью функции train_test_split из sklearn, выход - в data/interim вместе с неразделенными train и test данными.

3)  Генерация признаков<br />
Происходит в стейдже feature_generating. Заполняются пустые ячейки c помощью SimpleImputer по самому встречаемому для категориальных столбцов и по медиане для числовых столбцов, а также делается target encoding с помощью класса TargetEncoder, и label encoding с помощью label encoder из sklearn выход - в data/processed.
 
4)  Обучение модели<br />
  1.Происходит в стейдже train_models. В ходе треникровки с помощью gridSearchCV выбирается лучшие параметры для catboost модели и для RandomForestRegressor. Модели     сохраняются в папку models. Для RandomForestRegressor моделей создаются два пайплайна - один с label_encoder'ом, второй - с target_encoder'ом.
  
5)  Оценка модели по метрике качества, выбранном в первом пункте на val датасете и сохранение метрик / графиков.<br />
  Происходит в стейдже val_predict_count_metrics. Сохраняет метрики в reports/report.json, графики - в reports/figures

6) Predict осуществляется с помощью наилучшей модели по результатам метрик в стейдже val_predict_count_metrics, результаты сбрасываются в папку data/external

В пайплайнах используется работа с категориальными признаками (label_encoding, target_encoding, также попробовал покрутить параметры для catboost'а в gridSearchCV).
Для управления данными и экспериментами использован DVC
